{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KYC Funnel Analysis: Data Cleaning & Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "- Purpose: clean raw KYC exports, create binary flags for common failure modes, and prepare features for modeling and cohort analysis.\n",
    "- Steps: load data, apply heuristics for fraud/quality/tech failures, impute missing categorical fields, create combined features, and build a simple baseline model.\n",
    "- Notes: keep transformations transparent — these flags are useful both for analysis and as model inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyc_details = pd.read_csv('KYC_details.csv')\n",
    "kyc_summary = pd.read_csv('KYC_summary.csv')\n",
    "\n",
    "df = pd.merge(kyc_summary, kyc_details, on='user_reference', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_'] = pd.to_datetime(df['date_'])\n",
    "df['is_pass'] = df['decision_type'].isin(['PASSED', 'APPROVED']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = df[\n",
    "    (df['decision_type'].isin(['PASSED', 'APPROVED'])) & \n",
    "    (df['watchlist_screening_decision'].isna())\n",
    "]\n",
    "df_clean = df.drop(anomalies.index).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_keywords = [\n",
    "    'DIGITAL_COPY', 'MANIPULATED', 'FAKE', 'PUNCHED', \n",
    "    'MISMATCH_FRONT_BACK', 'PHOTOCOPY'\n",
    "]\n",
    "fraud_pattern = '|'.join(fraud_keywords)\n",
    "\n",
    "df_clean['is_confirmed_fraud'] = (\n",
    "    df_clean['image_checks_decision_details'].astype(str).str.contains(fraud_pattern, case=False, na=False) |\n",
    "    df_clean['usability_decision_details'].astype(str).str.contains('PHOTOCOPY', case=False, na=False)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_keywords = [\n",
    "    'GLARE', 'BLURRED', 'MISSING_PAGE', 'NOT_UPLOADED', \n",
    "    'DAMAGED_DOCUMENT', 'PART_OF_DOCUMENT_MISSING', 'PART_OF_DOCUMENT_HIDDEN',\n",
    "    'BAD_QUALITY', 'FACE_NOT_FULLY_VISIBLE', 'liveness_UNDETERMINED'\n",
    "]\n",
    "quality_pattern = '|'.join(quality_keywords)\n",
    "\n",
    "df_clean['is_quality_fail'] = (\n",
    "    df_clean['usability_decision_details'].astype(str).str.contains(quality_pattern, case=False, na=False) |\n",
    "    df_clean['liveness_decision_details'].astype(str).str.contains(quality_pattern, case=False, na=False)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['is_face_mismatch'] = (df_clean['similarity_decision_details'] == 'NO_MATCH').astype(int)\n",
    "df_clean['is_unsupported_doc'] = df_clean['usability_decision_details'].isin(['UNSUPPORTED_DOCUMENT_TYPE', 'NOT_A_DOCUMENT']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_fail_keywords = ['TECHNICAL_ERROR', 'MISMATCHING_DATAPOINTS', 'MISMATCH_HRZ_MRZ_DATA']\n",
    "tech_pattern = '|'.join(tech_fail_keywords)\n",
    "\n",
    "df_clean['is_tech_data_fail'] = (\n",
    "    df_clean['data_checks_decision_details'].astype(str).str.contains(tech_pattern, case=False, na=False) |\n",
    "    df_clean['extraction_decision_details'].astype(str).str.contains(tech_pattern, case=False, na=False)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 18, 25, 35, 45, 55, 100]\n",
    "labels = ['<18', '18-25', '26-35', '36-45', '46-55', '55+']\n",
    "\n",
    "df_clean['proxy_age'] = 2023 - pd.to_numeric(df_clean['year_birth'], errors='coerce')\n",
    "df_clean['age_group'] = pd.cut(df_clean['proxy_age'], bins=bins, labels=labels).astype(str).replace('nan', 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_fill = ['data_issuing_country', 'data_type', 'data_sub_type']\n",
    "for col in cols_to_fill:\n",
    "    df_clean[col] = df_clean[col].fillna('UNKOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['combo_country_type'] = df_clean['data_issuing_country'] + \"_\" + df_clean['data_type']\n",
    "df_clean['combo_country_subtype'] = df_clean['data_issuing_country'] + \"_\" + df_clean['data_sub_type']\n",
    "df_clean['combo_country_age'] = df_clean['data_issuing_country'] + \"_\" + df_clean['age_group']\n",
    "df_clean['combo_type_age'] = df_clean['data_type'] + \"_\" + df_clean['age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    'data_issuing_country',\n",
    "    'data_sub_type',\n",
    "    'combo_country_type',\n",
    "    'combo_country_subtype',\n",
    "    'combo_country_age',\n",
    "]\n",
    "\n",
    "binary_features = [\n",
    "    'is_confirmed_fraud',\n",
    "    'is_quality_fail',\n",
    "    'is_face_mismatch',\n",
    "    'is_tech_data_fail',\n",
    "    'is_unsupported_doc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean[categorical_cols+binary_features]\n",
    "y = df_clean['is_pass']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features_train = X_train[binary_features].copy()\n",
    "model_features_test = X_test[binary_features].copy()\n",
    "\n",
    "te = TargetEncoder(smooth=\"auto\", cv=5, random_state=42)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    te.fit(X_train[[col]], y_train)\n",
    "    model_features_train[f\"{col}_TE\"] = te.transform(X_train[[col]]).flatten()\n",
    "    model_features_test[f\"{col}_TE\"] = te.transform(X_test[[col]]).flatten()\n",
    "    \n",
    "    \n",
    "    counts = X_train[col].value_counts()\n",
    "    model_features_train[f\"{col}_CE\"] = X_train[col].map(counts).fillna(0)\n",
    "    model_features_test[f\"{col}_CE\"] = X_test[col].map(counts).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling notes:\n",
    "- Input: binary feature flags + target-encoded categorical features + count-encoding (CE) for stability.\n",
    "- Train/Test: a simple 70/30 split is used to create a baseline classifier.\n",
    "- Purpose: this model is a diagnostic baseline — we mainly use feature importance and SHAP to understand drivers of pass/fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(random_state=42)\n",
    "model.fit(model_features_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_proba = model.predict_proba(model_features_test)\n",
    "y_predict = model.predict(model_features_test)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the model (SHAP):\n",
    "- We use SHAP to get a global view of feature importance and per-sample explanations.\n",
    "- This helps validate that the binary flags and encoded categorical features behave as expected and surface any surprising drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(model_features_test)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, model_features_test, show=False)\n",
    "plt.title(\"SHAP Value Summary\", fontsize=16)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
